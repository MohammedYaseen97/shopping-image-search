{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval performance\n",
    "We compare the performance of the Xception and CLIP ViT models in terms of top-k accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import Street2ShopImageSimilarityTestDataset, evaluate_top_k_accuracies\n",
    "from models.xception import XceptionModel\n",
    "from models.clip_vit import CLIPViTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XceptionModel(embedding_dim=512).load('saved_models/xception_512.pth')\n",
    "test_dataset = Street2ShopImageSimilarityTestDataset(model, ratio=0.6)\n",
    "print(len(test_dataset))\n",
    "print(test_dataset[0])\n",
    "\n",
    "xception_accuracies, xception_visualization_data = evaluate_top_k_accuracies(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CLIPViTModel(embedding_dim=512).load('saved_models/clipvit_512.pth')\n",
    "test_dataset = Street2ShopImageSimilarityTestDataset(model, ratio=0.6)\n",
    "print(len(test_dataset))\n",
    "print(test_dataset[0])\n",
    "\n",
    "clipvit_accuracies, clipvit_visualization_data = evaluate_top_k_accuracies(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Extract accuracy values\n",
    "metrics = ['top_1_accuracy', 'top_3_accuracy', 'top_5_accuracy', 'top_10_accuracy']\n",
    "xception_values = [xception_accuracies[m] for m in metrics]\n",
    "clipvit_values = [clipvit_accuracies[m] for m in metrics]\n",
    "\n",
    "# Set up bar positions\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35  # Width of bars\n",
    "\n",
    "# Create figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Create bars\n",
    "rects1 = ax.bar(x - width/2, xception_values, width, label='Xception', color='skyblue')\n",
    "rects2 = ax.bar(x + width/2, clipvit_values, width, label='CLIP ViT', color='lightcoral')\n",
    "\n",
    "# Customize plot\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Model Performance Comparison')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['Top-1', 'Top-3', 'Top-5', 'Top-10'])\n",
    "ax.legend()\n",
    "\n",
    "# Add value labels on top of bars\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height:.2%}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', rotation=0)\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize example results\n",
    "def plot_retrieval_results(dataset, query_idx, retrieved_indices, num_results=5):\n",
    "    \"\"\"\n",
    "    Plot the query street photo and its top retrieved shop photos\n",
    "    \n",
    "    Args:\n",
    "        dataset: The test dataset instance\n",
    "        query_idx: Index of the query street photo\n",
    "        retrieved_indices: List of indices for retrieved shop photos\n",
    "        num_results: Number of top results to show\n",
    "    \"\"\"\n",
    "    # Get query image\n",
    "    query_item = dataset.test_dataset[query_idx]\n",
    "    query_image = query_item['street_photo_image']\n",
    "    \n",
    "    # Get retrieved images\n",
    "    retrieved_images = []\n",
    "    for idx in retrieved_indices[:num_results]:\n",
    "        retrieved_item = dataset.test_dataset[idx]\n",
    "        retrieved_images.append(retrieved_item['shop_photo_image'])\n",
    "    \n",
    "    # Create subplot\n",
    "    fig = plt.figure(figsize=(15, 3))\n",
    "    \n",
    "    # Plot query image\n",
    "    plt.subplot(1, num_results + 1, 1)\n",
    "    plt.imshow(query_image)\n",
    "    plt.title('Query\\n(Street Photo)')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Plot retrieved images\n",
    "    for i, img in enumerate(retrieved_images, 1):\n",
    "        plt.subplot(1, num_results + 1, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f'Top-{i}\\n(Shop Photo)')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Display a few example retrievals\n",
    "print(\"Example retrievals from CLIP ViT model:\")\n",
    "for query_idx, retrieved_indices in clipvit_visualization_data[:3]:\n",
    "    plot_retrieval_results(test_dataset, query_idx, retrieved_indices[0])\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "print(\"\\nExample retrievals from Xception model:\")\n",
    "for query_idx, retrieved_indices in xception_visualization_data[:3]:\n",
    "    plot_retrieval_results(test_dataset, query_idx, retrieved_indices[0])\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline to enhance retrieval performance\n",
    "Now we will build a pipeline to enhance the retrieval performance. Inspired by Pinterest image search pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
